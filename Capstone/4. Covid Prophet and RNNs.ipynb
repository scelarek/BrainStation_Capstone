{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Prophet Model](#toc1_1_)    \n",
    "    - [Prophet Tuned Model](#toc1_1_1_)    \n",
    "    - [Facebook Prophet Analysis](#toc1_1_2_)    \n",
    "      - [Preparing Data for Prophet](#toc1_1_2_1_)    \n",
    "    - [Recurrent Neural Networks (RNNs)](#toc1_1_3_)    \n",
    "      - [Data Preprocessing for RNNs](#toc1_1_3_1_)    \n",
    "      - [Building and Training the RNN](#toc1_1_3_2_)    \n",
    "      - [Predictions and Evaluation](#toc1_1_3_3_)    \n",
    "- [Code of the dead](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Prophet Model](#toc0_)\n",
    "- Prophet model expects the dataset to be named a specific way. We will rename our dataframe columns before feeding it into the model.\n",
    "    - Datetime column named: `ds`\n",
    "    - target : `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions used in this notebook:\n",
      "Python version: 3.9.17 (main, Jul  5 2023, 21:22:06) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas version: 2.0.2\n",
      "Numpy version: 1.23.4\n",
      "Seaborn version: 0.12.2\n",
      "Matplotlib version: 3.7.1\n",
      "Scipy version: 1.10.1\n",
      "Statsmodels version: 0.14.0\n",
      "SKLearn version: 1.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samsickle\\AppData\\Local\\Temp\\ipykernel_33444\\1022261773.py:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "from capstone_functions import *\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.plot import plot_cross_validation_metric, plot_plotly\n",
    "import statsmodels.api as sm\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import scipy.stats as stats\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_parquet(\"../Data/master_df.parquet\")\n",
    "\n",
    "#prepare the data for prophet\n",
    "master_df = master_df.reset_index().rename(columns={'date':'ds', 'new_confirmed':'y'}).copy()\n",
    "\n",
    "master_df.info()\n",
    "master_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_rows = master_df.dropna().copy()\n",
    "\n",
    "no_null_col = master_df.dropna(axis=1).copy()\n",
    "\n",
    "cutoff=15\n",
    "cutoff_date = no_null_col.ds.max() - pd.Timedelta(days=cutoff)\n",
    "\n",
    "train_df = no_null_col[no_null_col.ds < cutoff_date].copy()\n",
    "test_df = no_null_col[no_null_col.ds >= cutoff_date].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[['ds','y']].copy()\n",
    "y_test = test_df[['ds','y']].copy()\n",
    "\n",
    "\n",
    "most_important = ['stringency_index', 'derived_reproduction_rate', 'new_bi_weekly_vaccinations', \n",
    "                'current_hospitalized_patients',  'excess_mortality', 'ds']\n",
    "\n",
    "X_train = train_df[most_important].copy()\n",
    "X_test = test_df[most_important].copy()\n",
    "\n",
    "val_eval_holder = pd.DataFrame().rename_axis('Validation Metric', axis=1)\n",
    "in_sample_eval_holder = pd.DataFrame().rename_axis('In-Sample Metric', axis=1)\n",
    "out_of_sample_eval_holder = pd.DataFrame().rename_axis('Out-of-Sample Metric', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model of Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_plotter(forecast_df, yhat_col='yhat', original_col='y_train'):\n",
    "    \"\"\"\n",
    "    Plots residual diagnostics and returns evaluation metrics for a forecast dataframe from Prophet.\n",
    "    \n",
    "    Parameters:\n",
    "    - forecast_df: DataFrame from Prophet prediction.\n",
    "    \n",
    "    Returns:\n",
    "    - scores: Series with R2, MAE, RMSE, and SMAPE scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate residuals and lags\n",
    "    residuals = (forecast_df[original_col] - forecast_df[yhat_col]).dropna()\n",
    "    lags = int(min(20, round(len(residuals)/3) - 1))\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "    # Plot Histogram\n",
    "    sns.histplot(residuals, kde=True,  ax=ax[0,0])\n",
    "    ax[0,0].set_title(\"Histogram of Residuals\")\n",
    "    ax[0,0].set_xlabel(\"Residual\")\n",
    "    ax[0,0].set_ylabel(\"Frequency\")\n",
    "    ax[0,0].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # QQ Plot\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=ax[0,1])\n",
    "    ax[0,1].set_title(\"Q-Q Plot of Residuals\")\n",
    "    ax[0,1].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # ACF and PACF plots\n",
    "    sm.graphics.tsa.plot_acf(residuals, lags=lags, ax=ax[1,0])\n",
    "    sm.graphics.tsa.plot_pacf(residuals, lags=lags, ax=ax[1,1])\n",
    "    \n",
    "    ax[1,0].set_title(\"ACF of Residuals\")\n",
    "    ax[1,1].set_title(\"PACF of Residuals\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    # Evaluation Metrics\n",
    "    r2 = r2_score(forecast_df[original_col], forecast_df[yhat_col])\n",
    "    mae = mean_absolute_error(forecast_df[original_col], forecast_df[yhat_col])\n",
    "    rmse = mean_squared_error(forecast_df[original_col], forecast_df[yhat_col], squared=False)\n",
    "    smape_score = smape(forecast_df[original_col], forecast_df[yhat_col])\n",
    "    \n",
    "    scores = pd.Series({\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'SMAPE': smape_score\n",
    "    })\n",
    "    \n",
    "    return scores #, residuals\n",
    "\n",
    "# residual_plotter(forecast_df.dropna(subset='y_train'), yhat_col='yhat', original_col='y_train')\n",
    "# residual_plotter(forecast_df.dropna(subset='y_test'), yhat_col='yhat', original_col='y_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[most_important]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_df_complete(model, y_train, y_test, exogenous_df=None):\n",
    "\n",
    "    prophet_model_df = model.make_future_dataframe(15, freq='D', include_history=True)\n",
    "    \n",
    "    if master_df is not None:\n",
    "        prophet_model_df = prophet_model_df.merge(master_df, on='ds', how='left')\n",
    "\n",
    "    forecast_df = model.predict(prophet_model_df)\n",
    "    \n",
    "    \n",
    "    forecast_df = forecast_df.merge(y_train, on='ds', how='left').copy()\n",
    "    forecast_df = forecast_df.merge(y_test, on='ds', how='left', suffixes = ['_train', '_test']).copy()\n",
    "    \n",
    "    \n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Prophet().fit(y_train)\n",
    "\n",
    "\n",
    "forecast_df = forecast_df_complete(model, y_train, y_test)\n",
    "\n",
    "\n",
    "# Generate the Prophet forecast plot\n",
    "fig = plot_plotly(model, forecast_df)\n",
    "\n",
    "# Add the test actual data points\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.ds, \n",
    "    y=y_test.y, \n",
    "    mode='lines', \n",
    "    name='Historical Predictions', \n",
    "    line=dict(color='green')\n",
    "))\n",
    "\n",
    "# Add titles and labels\n",
    "fig.update_layout(\n",
    "    title=\"Prophet Model Forecast vs Actual Data\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Value\",\n",
    "    legend_title=\"Legend\"\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = model.plot_components(forecast_df)\n",
    "fig.suptitle('Seasonal Component Breakdown of Forecasted COVID-19 Cases', y=1.05, fontsize=16)\n",
    "fig.show();\n",
    "# Using the function on the sample dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_sample_eval_holder['Base Prophet Model'] = residual_plotter(forecast_df.dropna(subset='y_train'), yhat_col='yhat', original_col='y_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_eval_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_cv = cross_validation(\n",
    "    model, \n",
    "    initial=f\"366 days\", \n",
    "    period=f\"15 days\", \n",
    "    horizon=f\"15 days\",\n",
    "    parallel=\"processes\")\n",
    "\n",
    "val_eval_holder['Base Prophet Model'] = pd.to_numeric(performance_metrics(df_cv).mean().drop(index='horizon'))\n",
    "\n",
    "plot_cross_validation_metric(df_cv, metric='rmse')\n",
    "\n",
    "plt.title('RMSE for COVID-19 Forecasting using Prophet');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "out_of_sample_eval_holder['Base Prophet Model'] = residual_plotter(forecast_df.dropna(subset='y_test'), yhat_col='yhat', original_col='y_test')\n",
    "\n",
    "\n",
    "# with open('serialized_model.json', 'w') as fout:\n",
    "#     fout.write(model_to_json(model))  # Save model\n",
    "\n",
    "# with open('serialized_model.json', 'r') as fin:\n",
    "#     model = model_from_json(fin.read())  # Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(val_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))\n",
    "display(in_sample_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))\n",
    "# display(out_of_sample_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Prophet Tuned Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_force = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brute_force:\n",
    "    # Python\n",
    "    import itertools\n",
    "\n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': np.logspace(-2.5,-1.5, 5),\n",
    "        'seasonality_prior_scale': np.logspace(-1.5,1, 5),\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "    mae = []\n",
    "    smape = []\n",
    "    coverage = []\n",
    "\n",
    "\n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in all_params:    \n",
    "        m = Prophet(**params).fit(y_train)  # Fit model with given params\n",
    "        \n",
    "        df_cv = cross_validation(\n",
    "            m, \n",
    "            initial=f\"366 days\", \n",
    "            period=f\"15 days\", \n",
    "            horizon=f\"15 days\",\n",
    "            parallel=\"processes\")\n",
    "\n",
    "        \n",
    "        df_p = performance_metrics(df_cv, rolling_window=29)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        mae.append(df_p['mae'].values[0])\n",
    "        smape.append(df_p['smape'].values[0])\n",
    "        coverage.append(df_p['coverage'].values[0])\n",
    "        \n",
    "    # Find the best parameters\n",
    "\n",
    "    tuning_results1 = pd.DataFrame(all_params)\n",
    "    tuning_results1['rmse'] = rmses\n",
    "    tuning_results1['mae'] = mae\n",
    "    tuning_results1['smape'] = smape\n",
    "    tuning_results1['coverage'] = coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brute_force:\n",
    "    best_params = all_params[np.argmin(rmses)]\n",
    "    print(best_params)\n",
    "\n",
    "\n",
    "    tuning_results1['compo'] = (tuning_results['rmse'] + tuning_results1['mae']) * tuning_results1['smape']\n",
    "\n",
    "    tuning_results1.sort_values(by='changepoint_prior_scale').style.background_gradient(cmap='coolwarm', subset=['smape','mae', 'rmse', 'compo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brute_force:\n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': np.logspace(-2, -1, 7),\n",
    "        'seasonality_prior_scale': np.logspace(-2, 2, 7),\n",
    "    }\n",
    "\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "    mae = []\n",
    "    smape = []\n",
    "    coverage = []\n",
    "\n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in all_params:    \n",
    "        m = Prophet(**params).fit(y_train)  # Fit model with given params\n",
    "        \n",
    "        df_cv = cross_validation(\n",
    "            m, \n",
    "            initial=f\"366 days\", \n",
    "            period=f\"15 days\", \n",
    "            horizon=f\"15 days\",\n",
    "            parallel=\"processes\")\n",
    "\n",
    "        df_p = performance_metrics(df_cv, rolling_window=29)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        mae.append(df_p['mae'].values[0])\n",
    "        smape.append(df_p['smape'].values[0])\n",
    "        coverage.append(df_p['coverage'].values[0])\n",
    "\n",
    "    # Find the best parameters\n",
    "\n",
    "    tuning_results = pd.DataFrame(all_params)\n",
    "    tuning_results['rmse'] = rmses\n",
    "    tuning_results['mae'] = mae\n",
    "    tuning_results['smape'] = smape\n",
    "    tuning_results['coverage'] = coverage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brute_force:\n",
    "    best_params = all_params[np.argmin(rmses)]\n",
    "    print(best_params)\n",
    "\n",
    "\n",
    "    tuning_results['compo'] = ((tuning_results['rmse'] + tuning_results['mae']) / 2) / y_train.std()[1]\n",
    "    tuning_results['compo2'] = (tuning_results['rmse'] + tuning_results['mae']) * tuning_results['smape'] / y_train.std()[1]\n",
    "\n",
    "    tuning_results.sort_values(by='compo').head(15).style.background_gradient(cmap='coolwarm', subset=['smape','mae', 'rmse', 'compo', 'compo2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2 = Prophet(changepoint_prior_scale = 0.031623, seasonality_prior_scale = 0.046416)\n",
    "model2.add_country_holidays(country_name='US')\n",
    "\n",
    "model2.fit(y_train)\n",
    "# changepoint_prior_scale = 0.031623\n",
    "# seasonality_prior_scale = 0.046416\n",
    "\n",
    "forecast_df = forecast_df_complete(model2, y_train, y_test)\n",
    "\n",
    "\n",
    "# Generate the Prophet forecast plot\n",
    "fig = plot_plotly(model2, forecast_df)\n",
    "\n",
    "# Add the test actual data points\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.ds, \n",
    "    y=y_test.y, \n",
    "    mode='lines', \n",
    "    name='Historical Predictions', \n",
    "    line=dict(color='green')\n",
    "))\n",
    "\n",
    "# Add titles and labels\n",
    "fig.update_layout(\n",
    "    title=\"Tuned Prophet Model Forecast vs Actual Data\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Value\",\n",
    "    legend_title=\"Legend\"\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = model2.plot_components(forecast_df)\n",
    "fig.suptitle('Seasonal Component Breakdown of Forecasted COVID-19 Cases', y=1.05, fontsize=16)\n",
    "fig.show();\n",
    "# Using the function on the sample dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_sample_eval_holder['Tuned Prophet Model'] = residual_plotter(forecast_df.dropna(subset='y_train'), yhat_col='yhat', original_col='y_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cv = cross_validation(\n",
    "    model2, \n",
    "    initial=f\"366 days\", \n",
    "    period=f\"15 days\", \n",
    "    horizon=f\"15 days\",\n",
    "    parallel=\"processes\")\n",
    "\n",
    "val_eval_holder['Tuned Prophet Model'] = pd.to_numeric(performance_metrics(df_cv).mean().drop(index='horizon'))\n",
    "\n",
    "plot_cross_validation_metric(df_cv, metric='rmse')\n",
    "\n",
    "plt.title('RMSE for COVID-19 Forecasting using Prophet');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "out_of_sample_eval_holder['Tuned Prophet Model'] = residual_plotter(forecast_df.dropna(subset='y_test'), yhat_col='yhat', original_col='y_test')\n",
    "\n",
    "\n",
    "# with open('serialized_model.json', 'w') as fout:\n",
    "#     fout.write(model_to_json(model))  # Save model\n",
    "\n",
    "# with open('serialized_model.json', 'r') as fin:\n",
    "#     model = model_from_json(fin.read())  # Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(val_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))\n",
    "display(in_sample_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))\n",
    "# display(out_of_sample_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_2_'></a>[Facebook Prophet Analysis](#toc0_)\n",
    "\n",
    "Facebook Prophet is designed for forecasting time series data. Let's see how we can use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_train = pd.merge(X_train, y_train, on = ['ds'])\n",
    "\n",
    "exog_test = pd.merge(X_test, y_test, on = ['ds'])\n",
    "\n",
    "X_train_full = train_df.drop(columns=['y','ds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(X_train_full):\n",
    "    # Drop columns: 'current_hospitalized_patients', 'current_intensive_care_patients' and 20 other columns\n",
    "    columns_to_keep = ['current_hospitalized_patients', 'current_intensive_care_patients', 'cancel_events', 'derived_reproduction_rate', \n",
    "                'excess_mortality', 'gatherings_restrictions', 'information_campaigns', 'internal_movement_restrictions', 'international_movement_restrictions', \n",
    "                'school_closing', 'sig_recovery_rate', 'stay_home_restrictions', 'stringency_index', 'testing_policy', 'transport_closing', 'workplace_closing', \n",
    "                'dayofweek', 'quarter', 'month', 'new_bi_weekly_vaccinations', 'fatal', 'kap_mortality_rate']\n",
    "    \n",
    "    \n",
    "    X_train_full = X_train_full.loc[:, columns_to_keep]\n",
    "    return X_train_full\n",
    "\n",
    "\n",
    "# 'susceptible'\n",
    "\n",
    "X_train_full = clean_data(X_train_full.copy())\n",
    "X_train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.columns\n",
    "\n",
    "X_train_full = add_constant(X_train_full)\n",
    "\n",
    "#  VIF values\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_train_full.columns\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_full.values, i) for i in range(X_train_full.shape[1])]\n",
    "display(vif_data.sort_values(by='VIF', ascending=False).style.background_gradient(cmap='coolwarm', vmax=10))\n",
    "\n",
    "\n",
    "X_train_full.drop(columns=['const'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brute_force:\n",
    "    # Python\n",
    "\n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': np.logspace(-2.5,-1.5, 4),\n",
    "        'seasonality_prior_scale': np.logspace(-1.5,1, 4),\n",
    "        'holidays_prior_scale': np.logspace(-2,1, 4),\n",
    "    }\n",
    "\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "    mae = []\n",
    "    smape = []\n",
    "    coverage = []\n",
    "\n",
    "\n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in tqdm(all_params):    \n",
    "        m = Prophet(**params) # Fit model with given params\n",
    "        m.add_country_holidays(country_name='US')\n",
    "\n",
    "        for i in X_train_full.columns:\n",
    "            m.add_regressor(i, prior_scale = .5, standardize='auto', mode='additive')\n",
    "\n",
    "        m.fit(pd.concat([X_train_full, y_train], axis=1))\n",
    "\n",
    "        df_cv = cross_validation(\n",
    "            m, \n",
    "            initial=f\"366 days\", \n",
    "            period=f\"15 days\", \n",
    "            horizon=f\"15 days\",\n",
    "            parallel=\"processes\")\n",
    "\n",
    "        \n",
    "        df_p = performance_metrics(df_cv, rolling_window=29)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        mae.append(df_p['mae'].values[0])\n",
    "        smape.append(df_p['smape'].values[0])\n",
    "        coverage.append(df_p['coverage'].values[0])\n",
    "        \n",
    "    # Find the best parameters\n",
    "\n",
    "    tuning_results1 = pd.DataFrame(all_params)\n",
    "    tuning_results1['rmse'] = rmses\n",
    "    tuning_results1['mae'] = mae\n",
    "    tuning_results1['smape'] = smape\n",
    "    tuning_results1['coverage'] = coverage\n",
    "\n",
    "    tuning_results1\n",
    "\n",
    "    best_params = all_params[np.argmin(rmses)]\n",
    "    print(best_params)\n",
    "\n",
    "\n",
    "    tuning_results1['compo'] = (tuning_results1['rmse'] + tuning_results1['mae']) * tuning_results1['smape']\n",
    "\n",
    "    tuning_results1.sort_values(by='rmse').style.background_gradient(cmap='coolwarm', subset=['smape','mae', 'rmse', 'compo', 'coverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = Prophet(changepoint_prior_scale = 0.031623, seasonality_prior_scale = 0.046416)\n",
    "\n",
    "# for i in X_train.columns[:-2]:\n",
    "#     model3.add_regressor(i, prior_scale=0.5, mode='additive')\n",
    "\n",
    "# model3.fit(exog_train)\n",
    "\n",
    "\n",
    "\n",
    "# title= 'Prophet Tuned and Sparse Exogenous Model 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Prophet(changepoint_prior_scale = 0.031623, seasonality_prior_scale = 0.046416, growth='flat')\n",
    "model3.add_country_holidays(country_name='US')\n",
    "\n",
    "for i in X_train_full.columns:\n",
    "    model3.add_regressor(i, prior_scale = .5, standardize='auto', mode='additive')\n",
    "\n",
    "model3.fit(pd.concat([X_train_full, y_train], axis=1))\n",
    "\n",
    "\n",
    "title= 'Prophet Tuned and Big Exogenous Model 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_ready = pd.concat([y_train, X_train_full], axis=1).copy()\n",
    "# big_ready.iloc[:,1:] = big_ready.iloc[:,1:].apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna(axis=0, how='any').copy()\n",
    "\n",
    "# model3 = Prophet(changepoint_prior_scale = 0.003162, seasonality_prior_scale = 0.215443, holidays_prior_scale = 0.100000, growth='flat')\n",
    "# model3.add_country_holidays(country_name='US')\n",
    "\n",
    "# for i in big_ready.columns[2:]:\n",
    "#     model3.add_regressor(i, prior_scale = .5, standardize='auto', mode='additive')\n",
    "\n",
    "# model3.fit(big_ready)\n",
    "\n",
    "# title = 'Prophet Super Tuned and Big Exogenous Model 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast_df = forecast_df_complete(model3, y_train, y_test, X_train_full)\n",
    "\n",
    "\n",
    "# Generate the Prophet forecast plot\n",
    "fig = plot_plotly(model3, forecast_df)\n",
    "\n",
    "# Add the test actual data points\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test.ds, \n",
    "    y=y_test.y, \n",
    "    mode='lines', \n",
    "    name='Historical Predictions', \n",
    "    line=dict(color='green')\n",
    "))\n",
    "\n",
    "# Add titles and labels\n",
    "fig.update_layout(\n",
    "    title=f\"{title} Forecast vs Actual Data\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Value\",\n",
    "    legend_title=\"Legend\"\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show();\n",
    "\n",
    "\n",
    "fig = model3.plot_components(forecast_df)\n",
    "fig.suptitle('Seasonal Component Breakdown of Forecasted COVID-19 Cases', y=1.05, fontsize=16)\n",
    "fig.show();\n",
    "\n",
    "\n",
    "\n",
    "# Using the function on the sample dataframe\n",
    "\n",
    "in_sample_eval_holder[f'{title} Prophet Model'] = residual_plotter(forecast_df.dropna(subset='y_train'), yhat_col='yhat', original_col='y_train')\n",
    "\n",
    "\n",
    "\n",
    "df_cv = cross_validation(\n",
    "    model3, \n",
    "    initial=f\"366 days\", \n",
    "    period=f\"15 days\", \n",
    "    horizon=f\"15 days\",\n",
    "    parallel=\"processes\")\n",
    "\n",
    "val_eval_holder[f'{title} Prophet Model'] = pd.to_numeric(performance_metrics(df_cv).mean().drop(index='horizon'))\n",
    "\n",
    "plot_cross_validation_metric(df_cv, metric='rmse')\n",
    "\n",
    "plt.title(f'RMSE for COVID-19 Forecasting using {title} Prophet Model');\n",
    "\n",
    "\n",
    "\n",
    "out_of_sample_eval_holder[f'{title} Prophet Model'] = residual_plotter(forecast_df.dropna(subset='y_test'), yhat_col='yhat', original_col='y_test')\n",
    "\n",
    "\n",
    "# with open('serialized_model.json', 'w') as fout:\n",
    "#     fout.write(model_to_json(model3))  # Save model3\n",
    "\n",
    "# with open('serialized_model.json', 'r') as fin:\n",
    "#     model3 = model_from_json(fin.read())  # Load model3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(val_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))\n",
    "display(in_sample_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))\n",
    "display(out_of_sample_eval_holder.style.background_gradient(cmap='coolwarm', axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
