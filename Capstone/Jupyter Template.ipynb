{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Statistics & Public Health 2: Data Analysis](#toc0_)\n",
    "\n",
    "Sam Celarek  \n",
    "Data Science   \n",
    "scelarek@gmail.com  \n",
    "\n",
    "June 4th, 2023\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[1. Introduction](#toc0_)\n",
    "\n",
    "In this project, we will perform a set of analyses on the relationship between different variables and the mosquito number, as well as the probability of finding West Nile Virus (WNV) at any particular time and location. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[1.1. Key Questions](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <a id='toc3_'></a>[2. Setup and Data Collection](#toc0_)\n",
    "\n",
    "We will be utilizing the cleaned mosquito tracking data from the city of Chicago, Illinois, spanning from 2008 to 2019 provided [here](link_to_dataset). This section will include the necessary libraries and modules for the analysis, as well as the data preparation steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import re\n",
    "from functools import reduce\n",
    "\n",
    "# initialize styling params\n",
    "plt.rcParams['figure.figsize'] = (8.0, 6.0) #setting figure size\n",
    "\n",
    "# Load the data\n",
    "\n",
    "# Display the first few rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_holder = \"C://Users/Samsickle/Documents/BrainStation_Capstone/Data/\"\n",
    "# C:\\Users\\Samsickle\\Documents\\BrainStation_Capstone\\Data\n",
    "\n",
    "# # time series data\n",
    "epid_df = pd.read_csv(f'{folder_holder}epidemiology.csv') # 1\n",
    "hospitalizations_df = pd.read_csv(f'{folder_holder}hospitalizations.csv') # 2\n",
    "vac_df = pd.read_csv(f'{folder_holder}vaccinations.csv') # 3\n",
    "mobility_df = pd.read_csv(f'{folder_holder}mobility.csv') # 4\n",
    "gov_response_df = pd.read_csv(f'{folder_holder}oxford-government-response.csv') # 5\n",
    "weather_df = pd.read_csv(f'{folder_holder}weather.csv') # 6\n",
    "\n",
    "timeland_df = [epid_df, hospitalizations_df, mobility_df, vac_df, gov_response_df, weather_df]\n",
    "\n",
    "# # location dfs\n",
    "geography_df = pd.read_csv(f'{folder_holder}geography.csv') #1\n",
    "health_df = pd.read_csv(f'{folder_holder}health.csv') #2\n",
    "demographics_df = pd.read_csv(f'{folder_holder}demographics.csv') #3\n",
    "economics_df = pd.read_csv(f'{folder_holder}economy.csv') #4\n",
    "locationland_df = [geography_df, health_df, demographics_df, economics_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(df):\n",
    "    # Filter rows based on column: 'location_key'\n",
    "    df = df[df['location_key'].str.contains(r\"^(US|CA|DE|GB|FR|JP|AU|BR|ZA|IN)$\", na=False)]\n",
    "    \n",
    "    # Change column type to datetime64[ns] for column: 'date'\n",
    "    try:\n",
    "        df = df.astype({'date': 'datetime64[ns]'})\n",
    "    except:\n",
    "        pass\n",
    "    # Change column type to category for column: 'location_key'\n",
    "    df = df.astype({'location_key': 'category'})\n",
    "    return df\n",
    "\n",
    "\n",
    "time_series_dfs = list(map(clean_data, timeland_df))\n",
    "\n",
    "# Assume dfs is your list of dataframes\n",
    "time_series_dfs = reduce(lambda left,right: pd.merge(left,right,on=['location_key', 'date'], how='left'), time_series_dfs).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_series_dfs.to_pickle('../Data/time_series_dfs.pkl')\n",
    "time_series_dfs = pd.read_pickle('../Data/time_series_dfs.pkl')\n",
    "\n",
    "time_series_dfs.sample(3)\n",
    "\n",
    "folder_holder = \"C://Users/Samsickle/Documents/BrainStation_Capstone/Data/\"\n",
    "# C:\\Users\\Samsickle\\Documents\\BrainStation_Capstone\\Data\n",
    "\n",
    "# # # time series data\n",
    "# epid_df = pd.read_csv(f'{folder_holder}epidemiology.csv') # 1\n",
    "# hospitalizations_df = pd.read_csv(f'{folder_holder}hospitalizations.csv') # 2\n",
    "# vac_df = pd.read_csv(f'{folder_holder}vaccinations.csv') # 3\n",
    "# mobility_df = pd.read_csv(f'{folder_holder}mobility.csv') # 4\n",
    "# gov_response_df = pd.read_csv(f'{folder_holder}oxford-government-response.csv') # 5\n",
    "# weather_df = pd.read_csv(f'{folder_holder}weather.csv') # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location_key</th>\n",
       "      <th>new_confirmed</th>\n",
       "      <th>new_deceased</th>\n",
       "      <th>new_recovered</th>\n",
       "      <th>new_tested</th>\n",
       "      <th>cumulative_confirmed</th>\n",
       "      <th>cumulative_deceased</th>\n",
       "      <th>cumulative_recovered</th>\n",
       "      <th>cumulative_tested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date location_key  new_confirmed  new_deceased  new_recovered  \\\n",
       "0  2020-01-01           AD            0.0           0.0            NaN   \n",
       "1  2020-01-02           AD            0.0           0.0            NaN   \n",
       "2  2020-01-03           AD            0.0           0.0            NaN   \n",
       "3  2020-01-04           AD            0.0           0.0            NaN   \n",
       "4  2020-01-05           AD            0.0           0.0            NaN   \n",
       "\n",
       "   new_tested  cumulative_confirmed  cumulative_deceased  \\\n",
       "0         NaN                   0.0                  0.0   \n",
       "1         NaN                   0.0                  0.0   \n",
       "2         NaN                   0.0                  0.0   \n",
       "3         NaN                   0.0                  0.0   \n",
       "4         NaN                   0.0                  0.0   \n",
       "\n",
       "   cumulative_recovered  cumulative_tested  \n",
       "0                   NaN                NaN  \n",
       "1                   NaN                NaN  \n",
       "2                   NaN                NaN  \n",
       "3                   NaN                NaN  \n",
       "4                   NaN                NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epid_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here is a list of 10 countries that are often considered bellwethers for their regions and have good data collection, along with their 2-digit ISO country codes:\n",
    "\n",
    "United States (US)  \n",
    "Canada (CA)  \n",
    "Germany (DE)  \n",
    "United Kingdom (GB)  \n",
    "France (FR)  \n",
    "Japan (JP)  \n",
    "Australia (AU)  \n",
    "Brazil (BR)  \n",
    "South Africa (ZA)  \n",
    "India (IN)  \n",
    "These countries are often used as indicators for their respective regions due to their significant economic influence, political stability, and comprehensive data collection practices."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wireframe:\n",
    "\n",
    "1. Date and Location:\n",
    "    - 'date' - the day of the observations\n",
    "    - 'location_key' - the country of the observations\n",
    "\n",
    "2. COVID-19 Statistics:\n",
    "    - 'new_confirmed' (New Positive Cases) - the number of new confirmed cases of COVID-19, this includes some negative numbers to account for data corrections in the previous days, however because these numbers are aggregated accross a whole country, the negative numbers are often very small and remain positive\n",
    "    - 'new_deceased' (New Deaths) - the number of new deaths due to COVID-19 also shares the negative number problem\n",
    "    - 'new_hospitalized_patients' (New Hospitalizations)\n",
    "\n",
    "3. Mobility Data:\n",
    "    - 'mobility_retail_and_recreation'\n",
    "    - 'mobility_grocery_and_pharmacy'\n",
    "    - 'mobility_parks'\n",
    "    - 'mobility_transit_stations'\n",
    "    - 'mobility_workplaces'\n",
    "    - 'mobility_residential'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Vaccination Data:\n",
    "    - 'new_persons_vaccinated'\n",
    "    - 'cumulative_persons_vaccinated'\n",
    "    - 'new_persons_fully_vaccinated'\n",
    "    - 'cumulative_persons_fully_vaccinated'\n",
    "    - 'new_vaccine_doses_administered'\n",
    "    - 'cumulative_vaccine_doses_administered'\n",
    "\n",
    "5. Policy Measures:\n",
    "    - 'school_closing'\n",
    "    - 'workplace_closing'\n",
    "    - 'cancel_public_events'\n",
    "    - 'restrictions_on_gatherings'\n",
    "    - 'public_transport_closing'\n",
    "    - 'stay_at_home_requirements'\n",
    "    - 'restrictions_on_internal_movement'\n",
    "    - 'international_travel_controls'\n",
    "    - 'income_support'\n",
    "    - 'debt_relief'\n",
    "    - 'fiscal_measures'\n",
    "    - 'international_support'\n",
    "    - 'public_information_campaigns'\n",
    "    - 'testing_policy'\n",
    "    - 'contact_tracing'\n",
    "    - 'emergency_investment_in_healthcare'\n",
    "    - 'investment_in_vaccines'\n",
    "    - 'facial_coverings'\n",
    "    - 'vaccination_policy'\n",
    "    - 'stringency_index'\n",
    "\n",
    "6. Weather Data:\n",
    "    - 'average_temperature_celsius'\n",
    "    - 'minimum_temperature_celsius'\n",
    "    - 'maximum_temperature_celsius'\n",
    "    - 'rainfall_mm'\n",
    "    - 'snowfall_mm'\n",
    "    - 'dew_point'\n",
    "    - 'relative_humidity'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "location_df = list(map(clean_data, locationland_df))\n",
    "\n",
    "# Assume dfs is your list of dataframes\n",
    "location_df = reduce(lambda left,right: pd.merge(left,right,on='location_key', how='left'), location_df).copy()\n",
    "\n",
    "location_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "location_df.to_pickle('../Data/location_df.pkl')\n",
    "location_df = pd.read_pickle('../Data/location_df.pkl')\n",
    "\n",
    "location_df.sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe provides a comprehensive snapshot of COVID-19 data, mobility metrics, government restrictions, and weather conditions for specific locations on specific dates. Here's a brief overview of the columns:\n",
    "\n",
    "1. `Entry ID`: A unique identifier for each row in the dataframe.\n",
    "2. `Date`: The date for the day on which the data was recorded.\n",
    "3. `Location Key`: A code representing the location (10 different countries in total) for which the data is reported.\n",
    "\n",
    "4. `New Confirmed`: The number of new confirmed COVID-19 cases on the given date.\n",
    "5. `New Deceased`: The number of new COVID-19 related deaths on the given date.\n",
    "6. `New Recovered`: The number of new recoveries from COVID-19 on the given date.\n",
    "7. `New Tested`: The number of new COVID-19 tests conducted on the given date.\n",
    "\n",
    "8. `New Hospitalizations`: The number of new hospitalizations due to COVID-19 on the given date.\n",
    "9. `Current Hospitalizations`: The total number of current hospitalizations due to COVID-19 on the given date.\n",
    "\n",
    "10. `New Fully Vaccinated (29+ other Vaccination Columns)`: The number of new fully vaccinated individuals on the given date. There are 29 other columns related to vaccination data here too.\n",
    "\n",
    "11. `Retail and Recreation Mobility (5+ other Mobility Metrics)`: A measure of mobility in retail and recreation spaces, along with 5 other columns related to different aspects of mobility.\n",
    "\n",
    "12. `School Closing (19+ other Government Restrictions)`: A measure indicating whether schools were closed on the given date, along with 19 other columns related to different government restrictions.\n",
    "\n",
    "13. `Average Temp (6+ Other Weather Columns)`: The average temperature on the given date, along with 6 other columns related to different weather conditions.\n",
    "\n",
    "In total there are 9880 and 82 rows for 6.3mbs of data. The main way I could increase or decrease the size of the dataset would be to include more countries, regions, or counties in the analysis. For now this is my starter df.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
