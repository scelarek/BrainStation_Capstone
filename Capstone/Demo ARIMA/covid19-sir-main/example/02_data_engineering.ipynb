{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUpbQk_WOhdK"
      },
      "source": [
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/lisphilar/covid19-sir/HEAD?labpath=example%2F02_data_engineering.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data engineering\n",
        "With [Data preparation tutorial](https://github.com/lisphilar/covid19-sir/blob/master/example/01_data_preparation.ipynb), we prepared datasets (geospatial time-series data) to analyze.  As the next step of data engineering, we will perform the followings here.\n",
        "\n",
        "1. Data cleaning\n",
        "2. Data transformation\n",
        "3. Arithmetic operations\n",
        "4. EDA at a geospatial layer\n",
        "5. Data subsetting for a location and data complement\n",
        "6. EDA of subset\n",
        "\n",
        "Note that EDA = explanatory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "j1uZf_TbOHX_",
        "outputId": "b1aa9e32-b054-4566-e201-e87bf7a717fe"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import covsirphy as cs\n",
        "import numpy as np\n",
        "cs.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WbDfMogRp_v"
      },
      "source": [
        "We will use the recommended datasets at country-level data as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiAS8CkKRdCM",
        "outputId": "1d988331-a8bb-475f-a503-34affc86459f"
      },
      "outputs": [],
      "source": [
        "eng = cs.DataEngineer()\n",
        "eng.download(databases=[\"japan\", \"covid19dh\", \"owid\"])\n",
        "eng.all().info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipoi8IyqQcry"
      },
      "source": [
        "## 1. Data cleaning\n",
        "`DataEngineer().clean()` performs the following data cleaning functionalities. By applying a list of strings to `kinds` argument (eg. `kinds=[\"resample\"]`), we can specify the cleaning method(s).\n",
        "\n",
        "\n",
        "* \"convert_date\": Convert dtype of date column to pandas.Timestamp.\n",
        "* \"resample\": Resample records with dates.\n",
        "* \"fillna\": Fill NA values with '-' (layers) and the previous values and 0.\n",
        "\n",
        "For \"convert_date\", keyword arguments of pandas.to_datetime() including \"dayfirst (bool): whether date format is DD/MM or not\" can be used.\n",
        "\n",
        "For \"resample\", `date_range=<tuple of (str or None, str or None) or None>)` can be applied as keyword arguments to set the range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijYm41OwTPrM",
        "outputId": "d3fdf5e7-a750-4018-c092-2a7193fa9418"
      },
      "outputs": [],
      "source": [
        "eng.clean()\n",
        "eng.all().info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZHepK1WQhAP"
      },
      "source": [
        "## 2. Data transformation\n",
        "Transform all registered data, calculating the number of susceptible and infected cases. This is required to analyze real data with SIR-derived models.\n",
        "\n",
        "- Susceptible = Population - Confirmed\n",
        "- Infected = Confirmed - Fatal - Recovered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah3PPRmkUTPm"
      },
      "outputs": [],
      "source": [
        "main_variables = [\"Population\", \"Susceptible\", \"Confirmed\", \"Infected\", \"Fatal\", \"Recovered\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mQljdcP3TxNz",
        "outputId": "fad8ba31-56b7-47e0-fee7-b74956b3ea41"
      },
      "outputs": [],
      "source": [
        "eng.transform()\n",
        "eng.all(variables=main_variables).tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5K_aB8xUvtH"
      },
      "source": [
        "Recalculation of \"Population\" and \"Confirmed\" can be performed with `DataEngineer().inverse_transform()`, if necessary. (No impact with this example data.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qYJoz5-tVKFh",
        "outputId": "7f5bf2eb-4e98-454c-bdb1-5ff33aa57dc3"
      },
      "outputs": [],
      "source": [
        "eng.inverse_transform()\n",
        "eng.all(variables=main_variables).tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBQhq6sSVzaD"
      },
      "source": [
        "## 3. Arithmetic operations\n",
        "We can perform arithmetic operations to add new columns.\n",
        "\n",
        "* `.diff(column, suffix=\"_diff\", freq=\"D\")`: Calculate daily new cases with \"f(x>0) = F(x) - F(x-1), x(0) = 0 when F is cumulative numbers\".\n",
        "* `.add(columns, new=None, fill_value=0)`: Calculate element-wise addition with pandas.DataFrame.sum(axis=1), X1 + X2 + X3 +...\n",
        "* `.mul(columns, new=None, fill_value=0)`: Calculate element-wise multiplication with pandas.DataFrame.product(axis=1), X1 * X2 * X3 *...\n",
        "* `.sub(minuend, subtrahend, new=None, fill_value=0)`: Calculate element-wise subtraction with pandas.Series.sub(), minuend - subtrahend.\n",
        "* `.div(columns, new=None, fill_value=0)`: Calculate element-wise floating division with pandas.Series.div(), numerator / denominator.\n",
        "* `.assign(**kwargs))`: Assign a new column with pandas.DataFrame.assign().\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qK40wmeuXUw1",
        "outputId": "b8e6bbb6-dc3b-42ab-bf88-a43f08028654"
      },
      "outputs": [],
      "source": [
        "# Diff\n",
        "eng.diff(column=\"Confirmed\", suffix=\"_diff\", freq=\"D\")\n",
        "eng.all(variables=[\"Confirmed\", \"Confirmed_diff\"]).tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7lyYpt0ZXjX7",
        "outputId": "4e3b20d3-a6de-442b-e173-379a45601117"
      },
      "outputs": [],
      "source": [
        "# Addition\n",
        "eng.add(columns=[\"Fatal\", \"Recovered\"])\n",
        "eng.all(variables=[\"Fatal\", \"Recovered\", \"Fatal+Recovered\"]).tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1mKRoxUVX1zh",
        "outputId": "e3f2eafc-fd0d-4a16-c6f3-235aebc63427"
      },
      "outputs": [],
      "source": [
        "# Multiplication\n",
        "eng.mul(columns=[\"Confirmed\", \"Recovered\"])\n",
        "eng.all(variables=[\"Confirmed\", \"Recovered\", \"Confirmed*Recovered\"]).tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5gMi1iFIXB8K",
        "outputId": "0ba84b4a-dbd4-4487-a058-dc484a1dd84c"
      },
      "outputs": [],
      "source": [
        "# Division\n",
        "eng.div(numerator=\"Confirmed\", denominator=\"Tests\", new=\"Positive_rate\")\n",
        "# Assignment of new a new column\n",
        "eng.assign(**{\"Positive_rate_%\": lambda x: x[\"Positive_rate\"] * 100})\n",
        "eng.all(variables=[\"Tests\", \"Confirmed\", \"Positive_rate_%\"]).tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIXznltKQiCI"
      },
      "source": [
        "## 4. EDA at a geospatial layer\n",
        "`DataEngineer().layer()` returns the data at the selected layer in the date range.\n",
        "\n",
        "Arguments:\n",
        "\n",
        "* geo (tuple(list[str] or tuple(str) or str) or str or None): location names to specify the layer or None (the top level)\n",
        "* start_date (str or None): start date, like 22Jan2020\n",
        "* end_date (str or None): end date, like 01Feb2020\n",
        "* variables (list[str] or None): list of variables to add or None (all available columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "I2MkSuAOZd7L",
        "outputId": "e784e4cd-cbec-4778-c4b7-acae97efc7aa"
      },
      "outputs": [],
      "source": [
        "eng.layer().tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBEavSL6Z9uX"
      },
      "source": [
        "This dataset has only country-level data and `geo` should be country name. We can select the followings as `geo` argument for EDA at a geospatial layer when we have adequate data.\n",
        "\n",
        "* When `geo=None` or `geo=(None,)`, returns country-level data, assuming we have country/province/city as layers here.\n",
        "* When `geo=(\"Japan\",)` or `geo=\"Japan\"`, returns province-level data in Japan.\n",
        "* When `geo=([\"Japan\", \"UK\"],)`, returns province-level data in Japan and UK.\n",
        "* When `geo=(\"Japan\", \"Kanagawa\")`, returns city-level data in Kanagawa/Japan.\n",
        "* When `geo=(\"Japan\", [\"Tokyo\", \"Kanagawa\"])`, returns city-level data in Tokyo/Japan and Kanagawa/Japan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JB4eLvta5Hy"
      },
      "source": [
        "Additionally, we can create a choropleth map with a data at a geospatial layer on a date.\n",
        "\n",
        "arguments of `DataEngineer().choropleth()`:\n",
        "\n",
        "* geo (tuple(list[str] or tuple(str) or str) or str or None): location names to specify the layer or None (the top level)\n",
        "* variable (str): variable name to show\n",
        "* on (str or None): the date, like 22Jan2020, or None (the last date of each location)\n",
        "* title (str): title of the map\n",
        "* filename (str or None): filename to save the figure or None (display)\n",
        "* logscale (bool): whether convert the value to log10 scale values or not\n",
        "* directory (str): directory to save GeoJSON file of \"Natural Earth\" GitHub repository\n",
        "* natural_earth (str or None): title of GeoJSON file (without extension) of \"Natural Earth\" GitHub repository or None (automatically determined)\n",
        "* **kwargs: keyword arguments of the following classes and methods.\n",
        "    * matplotlib.pyplot.savefig(), matplotlib.pyplot.legend(), and\n",
        "    * pandas.DataFrame.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "V1K8EXyDayT9",
        "outputId": "c2cc0d77-70e4-4f7a-d32e-24bb6b1b4a11"
      },
      "outputs": [],
      "source": [
        "eng.choropleth(geo=None, variable=\"Confirmed\", title=\"Choropleth map: Confirmed on the last date of records\", filename=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I6lrlFEX5ck"
      },
      "source": [
        "## 5. Data subsetting for a location and data complement\n",
        "The dataset is a geospatial time-series data. By selecting a location, the dataset will be converted to a time-series data, which is easier to analyze."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WaTFw2EtQiFJ"
      },
      "source": [
        "### 5.1 Subsetting\n",
        "We will create a subset for selected location (eg. country, province/prefecture/state, city). Because the loaded dataset has country-level data, total values in United Kingdom (UK) on dates will be created here as an example.\n",
        "\n",
        "Arguments of `DataEngineer().subset()`:\n",
        "\n",
        "* geo (tuple(list[str] or tuple(str) or str) or str or None): location names to filter or None (total at the top level)\n",
        "* start_date (str or None): start date, like 22Jan2020\n",
        "* end_date (str or None): end date, like 01Feb2020\n",
        "* variables (list[str] or None): list of variables to add or None (all available columns)\n",
        "* complement (bool): whether perform data complement or not, True as default\n",
        "* get_dummies (bool): whether convert categorical variable into dummy variables or not, True as default\n",
        "* **Kwargs: keyword arguments for complement and default values\n",
        "    * recovery_period (int): expected value of recovery period [days], 17\n",
        "    * interval (int): expected update interval of the number of recovered cases [days], 2\n",
        "    * max_ignored (int): Max number of recovered cases to be ignored [cases], 100\n",
        "    * max_ending_unupdated (int): Max number of days to apply full complement, where max recovered cases are not updated [days], 14\n",
        "    * upper_limit_days (int): maximum number of valid partial recovery periods [days], 90\n",
        "    * lower_limit_days (int): minimum number of valid partial recovery periods [days], 7\n",
        "    * upper_percentage (float): fraction of partial recovery periods with value greater than upper_limit_days, 0.5\n",
        "    * lower_percentage (float): fraction of partial recovery periods with value less than lower_limit_days, 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZabXVUsySIPU"
      },
      "source": [
        "NOTE:  \n",
        "We can select the followings as `geo` argument for subsetting when we have adequate data.\n",
        "\n",
        "* When `geo=None` or `geo=(None,)`, returns global scale records (total values of all country-level data), assuming we have country/province/city as layers here.\n",
        "* When `geo=(\"Japan\",)` or `geo=\"Japan\"`, returns country-level data in Japan.\n",
        "* When `geo=([\"Japan\", \"UK\"],)`, returns country-level data of Japan and UK.\n",
        "* When `geo=(\"Japan\", \"Tokyo\")`, returns province-level data of Tokyo/Japan.\n",
        "* When `geo=(\"Japan\", [\"Tokyo\", \"Kanagawa\"])`, returns total values of province-level data of Tokyo/Japan and Kanagawa/Japan.\n",
        "* When `geo=(\"Japan\", \"Kanagawa\", \"Yokohama\")`, returns city-level data of Yokohama/Kanagawa/Japan.\n",
        "* When `geo=((\"Japan\", \"Kanagawa\", [\"Yokohama\", \"Kawasaki\"])`, returns total values of city-level data of Yokohama/Kanagawa/Japan and Kawasaki/Kanagawa/Japan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "iENpcOUYTd0G",
        "outputId": "ac7c0655-f0c2-45d6-a51f-19394fbde40b"
      },
      "outputs": [],
      "source": [
        "# Without complement\n",
        "without_df, status, status_dict = eng.subset(geo=\"UK\", complement=False)\n",
        "print(f\"{status}\\n\")\n",
        "pprint(status_dict)\n",
        "cs.line_plot(without_df[[\"Confirmed\", \"Fatal\", \"Recovered\"]], title=\"UK: records WITHOUT complement\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "9l4AWOqcQnEH",
        "outputId": "203f6a36-a54c-45c0-f4cc-5e5089be3f31"
      },
      "outputs": [],
      "source": [
        "# With complement (default)\n",
        "with_df, status, status_dict = eng.subset(geo=\"Japan\", complement=True)\n",
        "print(f\"{status}\\n\")\n",
        "pprint(status_dict)\n",
        "cs.line_plot(with_df[[\"Confirmed\", \"Fatal\", \"Recovered\"]], title=\"UK: records WITH complement\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBc-JlShXyOu"
      },
      "source": [
        "### 5.2 Details of data complement\n",
        "When `complement=True` (default), data complement will be performed for confirmed/fatal/recovered data. This may be required for analysis because reported cumulative values sometimes show decreasing by changing accidentally for an example. Additionally, some countries, including UK, do not report the number of recovered cases.\n",
        "\n",
        "The possible kinds of complement for each country are the following:\n",
        "\n",
        "* \"Monotonic_confirmed/fatal/recovered\" (monotonic increasing complement) Force the variable show monotonic increasing.\n",
        "* \"Full_recovered\" (full complement of recovered data) Estimate the number of recovered cases using the value of estimated average recovery period.\n",
        "* \"Partial_recovered\" (partial complement of recovered data) When recovered values are not updated for some days, extrapolate the values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jTq-GXnVpJP"
      },
      "source": [
        "### 5.3 Recovery period\n",
        "What is \"recovery period\"?  \n",
        "We defined \"recovery period\" as the time period between case confirmation and recovery (as it is subjectively defined per country). We can estimate the mode value of recovery period with class method `DataEngineer.recovery_period(data)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61jqclzxWCxU",
        "outputId": "630014d9-0b96-4df0-b04f-467c222c1dac"
      },
      "outputs": [],
      "source": [
        "jpn_df, *_ = eng.subset(geo=\"Japan\", variables=[\"Confirmed\", \"Fatal\", \"Recovered\"], complement=False)\n",
        "recovery_period = cs.DataEngineer.recovery_period(data=jpn_df)\n",
        "print(f\"Mode value of recovery period in Japan: {recovery_period} [days]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Sym5mFXnS7"
      },
      "source": [
        "Details of recovery period calculation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "CS84PGfbXusE",
        "outputId": "e2211a66-3c1e-4b49-bbda-2673a46e4dd6"
      },
      "outputs": [],
      "source": [
        "df = jpn_df.resample(\"D\").sum()\n",
        "df[\"diff\"] = df[\"Confirmed\"] - df[\"Fatal\"]\n",
        "df = df.loc[:, [\"diff\", \"Recovered\"]].unstack().reset_index()\n",
        "df.columns = [\"Variable\", \"Date\", \"Number\"]\n",
        "df[\"Days\"] = (df[\"Date\"] - df[\"Date\"].min()).dt.days\n",
        "df = df.pivot_table(values=\"Days\", index=\"Number\", columns=\"Variable\")\n",
        "df = df.interpolate(limit_area=\"inside\").dropna().astype(np.int64)\n",
        "df[\"Elapsed\"] = df[\"Recovered\"] - df[\"diff\"]\n",
        "df = df.loc[df[\"Elapsed\"] > 0]\n",
        "# Calculate mode value\n",
        "mode_value = round(df[\"Elapsed\"].mode().mean())\n",
        "df[\"Elapsed\"].plot.hist(title=f\"Histogram of elapsed days of recovery, mode value: {mode_value} days\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYLSYjYZaA5m"
      },
      "source": [
        "### 5.4 Alias of subsets\n",
        "We can register alias names of subsets with `DataEngineer().subset_alias()`.\n",
        "\n",
        "Arguments:  \n",
        "* alias (str or None): alias name or None (list-up alias names)\n",
        "* update (bool): force updating the alias when @alias is not None\n",
        "* **kwargs: keyword arguments of covsirphy.DataEngineer().subset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LNOkwRKaQm3",
        "outputId": "63ca258b-39d4-4872-933b-f0a926794188"
      },
      "outputs": [],
      "source": [
        "# Register\n",
        "sub1, *_ = eng.subset_alias(alias=\"UK_with\", geo=\"UK\", complement=True)\n",
        "# Retrieve with alias\n",
        "sub2, *_ = eng.subset_alias(alias=\"UK_with\")\n",
        "# Comparison\n",
        "sub1.equals(sub2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tubFNqgRObT"
      },
      "source": [
        "## 7. EDA of subset\n",
        "With explanatory data analysis, we will get the figure of datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fby-jSMtb7KY"
      },
      "source": [
        "### 7.1 Alias of variables\n",
        "We can specify variables with alias. For example, \"CIFR\" is equivalent to list `['Confirmed', 'Infected', 'Recovered', 'Fatal']`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "mtRJ2D0sclri",
        "outputId": "bde935ee-06be-4fa0-a9f9-9cfb8bce4066"
      },
      "outputs": [],
      "source": [
        "eng.subset(geo=\"Japan\", variables=\"CIRF\")[0].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8vRCthxczbK"
      },
      "source": [
        "All aliases can be checked with `DataEngineer().variables_alias()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SjIOtZPRSUf",
        "outputId": "4d363305-b26f-4280-f558-1c27380fb9e9"
      },
      "outputs": [],
      "source": [
        "eng.variables_alias()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4sftrXic-5M"
      },
      "source": [
        "We can register new alias \"p\" with `[\"Tests\", \"Confirmed\", \"Positive_rate_%\"]` as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "dyqvSZPIcFv4",
        "outputId": "74bf0aa0-a663-49ba-e1c1-0698d339522e"
      },
      "outputs": [],
      "source": [
        "# Register new alias\n",
        "eng.variables_alias(alias=\"p\", variables=[\"Tests\", \"Confirmed\", \"Positive_rate_%\"])\n",
        "# Check the contents of an alias\n",
        "eng.variables_alias(alias=\"p\")\n",
        "# Subsetting with the variable alias\n",
        "eng.subset_alias(alias=\"jp\", geo=\"Japan\", variables=\"p\")[0].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRHNdhpHd7Y_"
      },
      "source": [
        "### 7.2 Line plot\n",
        "Show data with line plot. We can select function `line_plot` or class `LinePlot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Eb2dNUCdjVb"
      },
      "outputs": [],
      "source": [
        "line_df, *_ = eng.subset_alias(alias=\"jp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUbB7XaNfSNP"
      },
      "source": [
        "With function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ka4av_kcedN9",
        "outputId": "bb28b8d3-274c-4e2c-d6e5-005254f7fbc6"
      },
      "outputs": [],
      "source": [
        "cs.line_plot(\n",
        "    line_df[\"Positive_rate_%\"],\n",
        "    title=\"Positive rate % in Japan\",\n",
        "    ylabel=\"Positive rate %\",\n",
        "    math_scale=False,\n",
        "    show_legend=False,\n",
        "    filename=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XSY2RTbfUb4"
      },
      "source": [
        "With class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "XXY-PDyEemL4",
        "outputId": "966a4e40-14be-4eaa-e2dc-87f02b58917c"
      },
      "outputs": [],
      "source": [
        "with cs.LinePlot(filename=None) as lp:\n",
        "    lp.plot(line_df[\"Positive_rate_%\"])\n",
        "    lp.title = \"Positive rate % in Japan\"\n",
        "    lp.x_axis(xlabel=None)\n",
        "    lp.y_axis(ylabel=\"Positive rate %\", math_scale=False)\n",
        "    lp.legend_hide()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoRQJ3V2goeO"
      },
      "source": [
        "### 7.3 Scatter plot\n",
        "Show data with scatter plot. We can select function `scatter_plot` or class `ScatterPlot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suqWC1TxfG4b"
      },
      "outputs": [],
      "source": [
        "sc_df, *_ = eng.subset_alias(alias=\"jp\")\n",
        "sc_df.rename(columns={\"Tests\": \"x\", \"Confirmed\": \"y\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "77i3iMO-g0ZZ",
        "outputId": "30a57153-6792-403f-c833-a7660313b298"
      },
      "outputs": [],
      "source": [
        "cs.scatter_plot(\n",
        "    sc_df,\n",
        "    title=\"Scatter plot\",\n",
        "    xlabel=\"Tests\", xlim=(0, None),\n",
        "    ylabel=\"Confirmed\",\n",
        "    filename=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "hnGua7mJhOB5",
        "outputId": "0a11beb5-f070-4a77-a2f2-6869b5945d35"
      },
      "outputs": [],
      "source": [
        "with cs.ScatterPlot(filename=None) as sp:\n",
        "    sp.plot(sc_df)\n",
        "    sp.title = \"Scatter plot\"\n",
        "    sp.x_axis(xlabel=\"Tests\", xlim=(0, None))\n",
        "    sp.y_axis(ylabel=\"Confirmed\")\n",
        "    sp.line_straight(p1=(0, 0), p2=(max(sc_df[\"x\"]), max(sc_df[\"y\"])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a6fyDXKiPnm"
      },
      "source": [
        "Thank you!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "02_data_engineering.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.8 ('.venv': poetry)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "22bb74880181aee4909a67ef083e714bf83db977b91038d43aef8b1870a4f681"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
